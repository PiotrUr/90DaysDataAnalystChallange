
# ğŸ“˜ Microsoft Fabric â€“ Study Notes (Day 11)

## ğŸ”· Module: Work with Delta Lake tables in Microsoft Fabric  
ğŸ”— [Link to module](https://learn.microsoft.com/en-us/training/modules/work-with-delta-lake-tables-microsoft-fabric/)

### ğŸ§  Key Concepts:
ğŸ”¹ **Delta Lake** is an open storage format that brings ACID transactions and schema enforcement to data lakes  
ğŸ”¹ In Microsoft Fabric, Delta Lake is the default format used for tables in Lakehouse  
ğŸ”¹ Delta Lake enables **versioned, reliable, and scalable** data operations

### ğŸ”§ What I practiced:
ğŸ”¹ Queried and managed **Delta tables** inside a Lakehouse using **SQL Endpoint**  
ğŸ”¹ Used SQL commands like `DESCRIBE HISTORY` to track changes and table versions  
ğŸ”¹ Ran **MERGE**, **INSERT**, **UPDATE**, and **DELETE** on Delta tables  
ğŸ”¹ Observed how schema evolution is handled when appending new data  
ğŸ”¹ Explored **time travel** capabilities through version-based queries

### âœ… Summary Takeaways:
ğŸ”¹ Delta Lake makes data lakes reliable for enterprise analytics  
ğŸ”¹ Time travel and version history are powerful tools for debugging and auditing  
ğŸ”¹ Fabric simplifies working with Delta by tightly integrating it into Lakehouses  
ğŸ”¹ The combination of SQL + version control = a strong foundation for trustworthy data pipelines
