
# ğŸ“˜ Microsoft Fabric â€“ Study Notes (Day 14)

## ğŸ”· Module: Work with Delta Lake tables in Microsoft Fabric  
ğŸ”— [Link to module](https://learn.microsoft.com/en-us/training/modules/work-delta-lake-tables-fabric/?WT.mc_id=cloudskillschallenge_b696c18d-7201-4aff-9c7d-d33014d93b25)

### ğŸ§  Key Concepts:
ğŸ”¹ **Delta Lake** enables ACID transactions and time travel capabilities within Microsoft Fabricâ€™s Lakehouse  
ğŸ”¹ Delta format is default in Lakehouses and supports schema enforcement, updates, deletes, and version history  
ğŸ”¹ Delta tables can be queried using both **Spark notebooks** and **SQL Endpoints**

### ğŸ”§ What I practiced:
ğŸ”¹ Used SQL commands like `DESCRIBE HISTORY` to view table versioning  
ğŸ”¹ Performed `MERGE`, `UPDATE`, `DELETE`, and `INSERT` operations on Delta tables  
ğŸ”¹ Observed how **schema evolution** behaves when appending new data  
ğŸ”¹ Verified time travel with version-based queries (e.g. `VERSION AS OF`)

### âœ… Summary Takeaways:
ğŸ”¹ Delta Lake brings structure, reliability, and flexibility to Lakehouse data  
ğŸ”¹ Being able to trace data changes and revert versions is a huge plus for auditing and debugging  
ğŸ”¹ SQL support makes it accessible even without Spark-specific skills  
ğŸ”¹ Fabric makes managing Delta tables smooth through both visual and code-based workflows
